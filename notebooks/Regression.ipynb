{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow       import keras\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics  import mean_absolute_error, median_absolute_error\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the dataset and parsing the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calexico East</td>\n",
       "      <td>California</td>\n",
       "      <td>2507</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>03/01/2019 12:00:00 AM</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>34447</td>\n",
       "      <td>POINT (-115.48433000000001 32.67524)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Van Buren</td>\n",
       "      <td>Maine</td>\n",
       "      <td>108</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>03/01/2019 12:00:00 AM</td>\n",
       "      <td>Rail Containers Full</td>\n",
       "      <td>428</td>\n",
       "      <td>POINT (-67.94271 47.16207)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otay Mesa</td>\n",
       "      <td>California</td>\n",
       "      <td>2506</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>03/01/2019 12:00:00 AM</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>81217</td>\n",
       "      <td>POINT (-117.05333 32.57333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nogales</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2604</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>03/01/2019 12:00:00 AM</td>\n",
       "      <td>Trains</td>\n",
       "      <td>62</td>\n",
       "      <td>POINT (-110.93361 31.340279999999996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trout River</td>\n",
       "      <td>New York</td>\n",
       "      <td>715</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>03/01/2019 12:00:00 AM</td>\n",
       "      <td>Personal Vehicle Passengers</td>\n",
       "      <td>16377</td>\n",
       "      <td>POINT (-73.44253 44.990010000000005)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Port Name       State  Port Code            Border  \\\n",
       "0  Calexico East  California       2507  US-Mexico Border   \n",
       "1      Van Buren       Maine        108  US-Canada Border   \n",
       "2      Otay Mesa  California       2506  US-Mexico Border   \n",
       "3        Nogales     Arizona       2604  US-Mexico Border   \n",
       "4    Trout River    New York        715  US-Canada Border   \n",
       "\n",
       "                     Date                      Measure  Value  \\\n",
       "0  03/01/2019 12:00:00 AM                       Trucks  34447   \n",
       "1  03/01/2019 12:00:00 AM         Rail Containers Full    428   \n",
       "2  03/01/2019 12:00:00 AM                       Trucks  81217   \n",
       "3  03/01/2019 12:00:00 AM                       Trains     62   \n",
       "4  03/01/2019 12:00:00 AM  Personal Vehicle Passengers  16377   \n",
       "\n",
       "                                Location  \n",
       "0   POINT (-115.48433000000001 32.67524)  \n",
       "1             POINT (-67.94271 47.16207)  \n",
       "2            POINT (-117.05333 32.57333)  \n",
       "3  POINT (-110.93361 31.340279999999996)  \n",
       "4   POINT (-73.44253 44.990010000000005)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_crossing = pd.read_csv('../data/Border_Crossing_Entry_Data.csv')    \n",
    "border_crossing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346732</th>\n",
       "      <td>Presidio</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2403</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>347</td>\n",
       "      <td>POINT (-104.39000000000001 29.56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345903</th>\n",
       "      <td>Whitlash</td>\n",
       "      <td>Montana</td>\n",
       "      <td>3321</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>Truck Containers Full</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-111.26000000000002 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345904</th>\n",
       "      <td>Jackman</td>\n",
       "      <td>Maine</td>\n",
       "      <td>104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>Truck Containers Full</td>\n",
       "      <td>2103</td>\n",
       "      <td>POINT (-70.4 45.81)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345905</th>\n",
       "      <td>Hidalgo</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2305</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>Truck Containers Full</td>\n",
       "      <td>9794</td>\n",
       "      <td>POINT (-98.27 26.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345906</th>\n",
       "      <td>Boundary</td>\n",
       "      <td>Washington</td>\n",
       "      <td>3015</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>Pedestrians</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-117.62999999999998 49)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Port Name       State  Port Code            Border        Date  \\\n",
       "346732  Presidio       Texas       2403  US-Mexico Border  1996-01-01   \n",
       "345903  Whitlash     Montana       3321  US-Canada Border  1996-01-01   \n",
       "345904   Jackman       Maine        104  US-Canada Border  1996-01-01   \n",
       "345905   Hidalgo       Texas       2305  US-Mexico Border  1996-01-01   \n",
       "345906  Boundary  Washington       3015  US-Canada Border  1996-01-01   \n",
       "\n",
       "                      Measure  Value                           Location  \n",
       "346732                 Trucks    347  POINT (-104.39000000000001 29.56)  \n",
       "345903  Truck Containers Full      0     POINT (-111.26000000000002 49)  \n",
       "345904  Truck Containers Full   2103                POINT (-70.4 45.81)  \n",
       "345905  Truck Containers Full   9794                POINT (-98.27 26.1)  \n",
       "345906            Pedestrians      0     POINT (-117.62999999999998 49)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_date(s): \n",
    "    date, *_ = s.strip().split()\n",
    "    [month, day, year] = list(map(int, date.split(sep='/')))\n",
    "    return datetime.date(year, month, day)\n",
    "    \n",
    "border_crossing['Date'] = border_crossing['Date'].apply(parse_date)\n",
    "border_crossing = border_crossing.sort_values(by='Date')\n",
    "border_crossing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll extract the year, month, and also keep a running count of the total number of months that have passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Total Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Calexico</td>\n",
       "      <td>California</td>\n",
       "      <td>2503</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Personal Vehicles</td>\n",
       "      <td>413457</td>\n",
       "      <td>POINT (-115.49806000000001 32.67889)</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Richford</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>203</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Train Passengers</td>\n",
       "      <td>30</td>\n",
       "      <td>POINT (-72.67832000000001 44.98588)</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>Eastport</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>3302</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Personal Vehicle Passengers</td>\n",
       "      <td>9719</td>\n",
       "      <td>POINT (-116.18027999999998 48.99944)</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Laurier</td>\n",
       "      <td>Washington</td>\n",
       "      <td>3016</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Rail Containers Full</td>\n",
       "      <td>196</td>\n",
       "      <td>POINT (-118.22302 48.99892)</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calexico East</td>\n",
       "      <td>California</td>\n",
       "      <td>2507</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>34447</td>\n",
       "      <td>POINT (-115.48433000000001 32.67524)</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Port Name       State  Port Code            Border        Date  \\\n",
       "527       Calexico  California       2503  US-Mexico Border  2019-03-01   \n",
       "526       Richford     Vermont        203  US-Canada Border  2019-03-01   \n",
       "525       Eastport       Idaho       3302  US-Canada Border  2019-03-01   \n",
       "523        Laurier  Washington       3016  US-Canada Border  2019-03-01   \n",
       "0    Calexico East  California       2507  US-Mexico Border  2019-03-01   \n",
       "\n",
       "                         Measure   Value  \\\n",
       "527            Personal Vehicles  413457   \n",
       "526             Train Passengers      30   \n",
       "525  Personal Vehicle Passengers    9719   \n",
       "523         Rail Containers Full     196   \n",
       "0                         Trucks   34447   \n",
       "\n",
       "                                 Location  Year  Month  Total Month  \n",
       "527  POINT (-115.49806000000001 32.67889)    23      2          278  \n",
       "526   POINT (-72.67832000000001 44.98588)    23      2          278  \n",
       "525  POINT (-116.18027999999998 48.99944)    23      2          278  \n",
       "523           POINT (-118.22302 48.99892)    23      2          278  \n",
       "0    POINT (-115.48433000000001 32.67524)    23      2          278  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_crossing['Year'] = border_crossing['Date'].apply(lambda d: d.year - 1996)\n",
    "border_crossing['Month'] = border_crossing['Date'].apply(lambda d: d.month - 1)\n",
    "\n",
    "def get_total_month(p):\n",
    "    (y,m) = p\n",
    "    return 12*y + m\n",
    "border_crossing['Total Month'] = list(map(get_total_month, zip(border_crossing['Year'], border_crossing['Month'])))\n",
    "\n",
    "border_crossing.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do to prepare the data is to one-hot encode the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Total Month</th>\n",
       "      <th>Port Name_Alcan</th>\n",
       "      <th>Port Name_Alexandria Bay</th>\n",
       "      <th>Port Name_Algonac</th>\n",
       "      <th>Port Name_Ambrose</th>\n",
       "      <th>Port Name_Anacortes</th>\n",
       "      <th>...</th>\n",
       "      <th>Measure_Pedestrians</th>\n",
       "      <th>Measure_Personal Vehicle Passengers</th>\n",
       "      <th>Measure_Personal Vehicles</th>\n",
       "      <th>Measure_Rail Containers Empty</th>\n",
       "      <th>Measure_Rail Containers Full</th>\n",
       "      <th>Measure_Train Passengers</th>\n",
       "      <th>Measure_Trains</th>\n",
       "      <th>Measure_Truck Containers Empty</th>\n",
       "      <th>Measure_Truck Containers Full</th>\n",
       "      <th>Measure_Trucks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346732</th>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345903</th>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345904</th>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>2103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345905</th>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>9794</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345906</th>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date  Value  Year  Month  Total Month  Port Name_Alcan  \\\n",
       "346732  1996-01-01    347     0      0            0                0   \n",
       "345903  1996-01-01      0     0      0            0                0   \n",
       "345904  1996-01-01   2103     0      0            0                0   \n",
       "345905  1996-01-01   9794     0      0            0                0   \n",
       "345906  1996-01-01      0     0      0            0                0   \n",
       "\n",
       "        Port Name_Alexandria Bay  Port Name_Algonac  Port Name_Ambrose  \\\n",
       "346732                         0                  0                  0   \n",
       "345903                         0                  0                  0   \n",
       "345904                         0                  0                  0   \n",
       "345905                         0                  0                  0   \n",
       "345906                         0                  0                  0   \n",
       "\n",
       "        Port Name_Anacortes  ...  Measure_Pedestrians  \\\n",
       "346732                    0  ...                    0   \n",
       "345903                    0  ...                    0   \n",
       "345904                    0  ...                    0   \n",
       "345905                    0  ...                    0   \n",
       "345906                    0  ...                    1   \n",
       "\n",
       "        Measure_Personal Vehicle Passengers  Measure_Personal Vehicles  \\\n",
       "346732                                    0                          0   \n",
       "345903                                    0                          0   \n",
       "345904                                    0                          0   \n",
       "345905                                    0                          0   \n",
       "345906                                    0                          0   \n",
       "\n",
       "        Measure_Rail Containers Empty  Measure_Rail Containers Full  \\\n",
       "346732                              0                             0   \n",
       "345903                              0                             0   \n",
       "345904                              0                             0   \n",
       "345905                              0                             0   \n",
       "345906                              0                             0   \n",
       "\n",
       "        Measure_Train Passengers  Measure_Trains  \\\n",
       "346732                         0               0   \n",
       "345903                         0               0   \n",
       "345904                         0               0   \n",
       "345905                         0               0   \n",
       "345906                         0               0   \n",
       "\n",
       "        Measure_Truck Containers Empty  Measure_Truck Containers Full  \\\n",
       "346732                               0                              0   \n",
       "345903                               0                              1   \n",
       "345904                               0                              1   \n",
       "345905                               0                              1   \n",
       "345906                               0                              0   \n",
       "\n",
       "        Measure_Trucks  \n",
       "346732               1  \n",
       "345903               0  \n",
       "345904               0  \n",
       "345905               0  \n",
       "345906               0  \n",
       "\n",
       "[5 rows x 267 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del border_crossing['Location']\n",
    "one_hot = border_crossing.copy()\n",
    "\n",
    "for col in ['Port Name', 'State', 'Port Code', 'Border', 'Measure']:\n",
    "    border_crossing[col] = border_crossing[col].astype('category')\n",
    "\n",
    "def one_hot_encode_categoricals(df):\n",
    "    df2 = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name == 'category':\n",
    "            dummies = pd.get_dummies(df[col], prefix=col)\n",
    "            df2[dummies.columns] = dummies\n",
    "            del df2[col]\n",
    "    return df2\n",
    "    \n",
    "one_hot = one_hot_encode_categoricals(border_crossing)\n",
    "one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(col):\n",
    "    max = col.max()\n",
    "    min = col.min()\n",
    "    return (col - min)/(max - min)\n",
    "\n",
    "def split_data(df, label_col, split=.9):\n",
    "    data = df.copy()\n",
    "    del data[label_col]\n",
    "    labels = df[label_col]\n",
    "    \n",
    "    len_total = len(df)\n",
    "    len_train = int(.9 * len_total)\n",
    "    len_test  = len_total - len_train\n",
    "    \n",
    "    train_input  = data.head(len_train).to_numpy()\n",
    "    train_labels = labels.head(len_train).to_numpy()\n",
    "\n",
    "    test_input  = data.tail(len_test).to_numpy()\n",
    "    test_labels = labels.tail(len_test).to_numpy()\n",
    "    \n",
    "    return train_input, train_labels, test_input, test_labels\n",
    "\n",
    "shuffled = one_hot.sample(frac=1)\n",
    "del shuffled['Date']\n",
    "train_input, train_labels, test_input, test_labels = split_data(shuffled, 'Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by applying a random forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=731)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=100,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=731, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(train_input, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916687680605362\n",
      "1724.268178334475\n"
     ]
    }
   ],
   "source": [
    "print(forest.score(test_input, test_labels))\n",
    "print(mean_absolute_error(test_labels, forest.predict(test_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this error into context, let's look at the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.467330e+05\n",
       "mean     2.818767e+04\n",
       "std      1.518588e+05\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      9.000000e+01\n",
       "75%      2.483000e+03\n",
       "max      4.447374e+06\n",
       "Name: Value, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_crossing['Value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most data is very small with respect to the maximum. So now I am curious if the model is consistently off, or if it strays infrequently, but severely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.94"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(test_labels, forest.predict(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests to me that the error is typically very small, but modest mistakes on the extremely large values greatly contribute to the average error.\n",
    "\n",
    "Now let's try to apply a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_hidden = len(border_crossing.columns)\n",
    "\n",
    "nn = tf.keras.Sequential([\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "nn.compile(loss = 'mse',\n",
    "           optimizer = tf.keras.optimizers.RMSprop(0.001),\n",
    "           metrics=['mae','mse']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 312059 samples\n",
      "Epoch 1/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 23692197926.3019 - mae: 37826.1992 - mse: 23692269568.0000\n",
      "Epoch 2/10\n",
      "312059/312059 [==============================] - 18s 58us/sample - loss: 22914004811.9430 - mae: 39176.7891 - mse: 22913951744.0000\n",
      "Epoch 3/10\n",
      "312059/312059 [==============================] - 19s 60us/sample - loss: 20997995608.1550 - mae: 36862.5664 - mse: 20997980160.0000\n",
      "Epoch 4/10\n",
      "312059/312059 [==============================] - 19s 61us/sample - loss: 18693955760.7026 - mae: 35461.2422 - mse: 18693969920.0000\n",
      "Epoch 5/10\n",
      "312059/312059 [==============================] - 19s 61us/sample - loss: 16008772831.7891 - mae: 31521.8691 - mse: 16008757248.0000\n",
      "Epoch 6/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 13347292078.8412 - mae: 26882.6367 - mse: 13347283968.0000\n",
      "Epoch 7/10\n",
      "312059/312059 [==============================] - 19s 61us/sample - loss: 10994039071.2489 - mae: 22795.0078 - mse: 10994041856.0000\n",
      "Epoch 8/10\n",
      "312059/312059 [==============================] - 19s 61us/sample - loss: 9177748658.7455 - mae: 19912.9766 - mse: 9177757696.0000\n",
      "Epoch 9/10\n",
      "312059/312059 [==============================] - 19s 60us/sample - loss: 7809007025.2612 - mae: 17601.2246 - mse: 7809009152.0000\n",
      "Epoch 10/10\n",
      "312059/312059 [==============================] - 19s 61us/sample - loss: 6808446310.4197 - mae: 15900.9209 - mse: 6808447488.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39ced29908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(train_input, train_labels, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5109485168.475284, 14217.426, 5109490000.0]\n",
      "2685.967041015625\n"
     ]
    }
   ],
   "source": [
    "print(nn.evaluate(test_input, test_labels, verbose=0))\n",
    "print(median_absolute_error(test_labels, nn.predict(test_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results aren't very encouraging. Let's try again after standardizing our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = one_hot.sample(frac=1)\n",
    "del shuffled['Date']\n",
    "shuffled['Value'] = standardize(shuffled['Value'])\n",
    "    \n",
    "train_input, train_labels, test_input, test_labels = split_data(shuffled, 'Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.Sequential([\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "nn.compile(loss = 'mse',\n",
    "           optimizer = tf.keras.optimizers.RMSprop(0.001),\n",
    "           metrics=['mae','mse']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 312059 samples\n",
      "Epoch 1/10\n",
      "312059/312059 [==============================] - 20s 63us/sample - loss: 0.0019 - mae: 0.0160 - mse: 0.0019s - loss: 0.0020 - mae: 0.0162 - mse\n",
      "Epoch 2/10\n",
      "312059/312059 [==============================] - 19s 61us/sample - loss: 2.0707e-04 - mae: 0.0045 - mse: 2.0707e-04\n",
      "Epoch 3/10\n",
      "312059/312059 [==============================] - 19s 61us/sample - loss: 1.7029e-04 - mae: 0.0041 - mse: 1.7029e-04\n",
      "Epoch 4/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 1.4964e-04 - mae: 0.0038 - mse: 1.4964e-04\n",
      "Epoch 5/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 1.4430e-04 - mae: 0.0038 - mse: 1.4430e-04\n",
      "Epoch 6/10\n",
      "312059/312059 [==============================] - 20s 63us/sample - loss: 1.3028e-04 - mae: 0.0035 - mse: 1.3028e-04\n",
      "Epoch 7/10\n",
      "312059/312059 [==============================] - 20s 63us/sample - loss: 1.2643e-04 - mae: 0.0034 - mse: 1.2643e-04\n",
      "Epoch 8/10\n",
      "312059/312059 [==============================] - 19s 60us/sample - loss: 1.2564e-04 - mae: 0.0034 - mse: 1.2564e-04\n",
      "Epoch 9/10\n",
      "312059/312059 [==============================] - 19s 59us/sample - loss: 1.2320e-04 - mae: 0.0034 - mse: 1.2320e-04\n",
      "Epoch 10/10\n",
      "312059/312059 [==============================] - 19s 60us/sample - loss: 1.2215e-04 - mae: 0.0034 - mse: 1.2215e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39cca06710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(train_input, train_labels, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.709803234830607e-05, 0.0024008516, 8.709803e-05]\n",
      "0.0002564825117588043\n"
     ]
    }
   ],
   "source": [
    "print(nn.evaluate(test_input, test_labels, verbose=0))\n",
    "print(median_absolute_error(test_labels, nn.predict(test_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare? What are the values after scaling back to the original range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13640.096058\n",
      "5292.37506\n"
     ]
    }
   ],
   "source": [
    "max = border_crossing['Value'].max()\n",
    "print(.003067 * max)\n",
    "print(.00119 * max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values appear to be slightly better. Now, let's just tweak some parameters of the neural network itself, such as the depth, loss function, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.Sequential([\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "nn.compile(loss = 'mse',\n",
    "           optimizer = tf.keras.optimizers.RMSprop(0.001),\n",
    "           metrics=['mae','mse']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 312059 samples\n",
      "Epoch 1/10\n",
      "312059/312059 [==============================] - 22s 69us/sample - loss: 0.0015 - mae: 0.0100 - mse: 0.0015\n",
      "Epoch 2/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 1.7904e-04 - mae: 0.0043 - mse: 1.7904e-04s - loss: 1.8743e-04\n",
      "Epoch 3/10\n",
      "312059/312059 [==============================] - 21s 66us/sample - loss: 1.2635e-04 - mae: 0.0034 - mse: 1.2635e-04\n",
      "Epoch 4/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 1.0593e-04 - mae: 0.0031 - mse: 1.0593e-04\n",
      "Epoch 5/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 9.8767e-05 - mae: 0.0030 - mse: 9.8767e-05\n",
      "Epoch 6/10\n",
      "312059/312059 [==============================] - 21s 66us/sample - loss: 8.9713e-05 - mae: 0.0028 - mse: 8.9712e-05\n",
      "Epoch 7/10\n",
      "312059/312059 [==============================] - 21s 66us/sample - loss: 8.3953e-05 - mae: 0.0027 - mse: 8.3953e-05\n",
      "Epoch 8/10\n",
      "312059/312059 [==============================] - 21s 66us/sample - loss: 8.1396e-05 - mae: 0.0027 - mse: 8.1396e-05\n",
      "Epoch 9/10\n",
      "312059/312059 [==============================] - 21s 66us/sample - loss: 7.8567e-05 - mae: 0.0026 - mse: 7.8568e-05\n",
      "Epoch 10/10\n",
      "312059/312059 [==============================] - 21s 66us/sample - loss: 7.6042e-05 - mae: 0.0024 - mse: 7.6042e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39ca8471d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(train_input, train_labels, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.920392145971672e-05, 0.0018306827, 6.92039e-05]\n",
      "0.0004271995276212692\n"
     ]
    }
   ],
   "source": [
    "print(nn.evaluate(test_input, test_labels, verbose=0))\n",
    "print(median_absolute_error(test_labels, nn.predict(test_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9882.065028\n",
      "3086.477556\n"
     ]
    }
   ],
   "source": [
    "max = border_crossing['Value'].max()\n",
    "print(.002222 * max)\n",
    "print(.000694 * max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems depth was very beneficial. Now let's try changing the loss function. I think mean absolute error might be better here than squared error, which will over-punish predictions on large numbers that are relatively accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.Sequential([\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "nn.compile(loss = 'mae',\n",
    "           optimizer = tf.keras.optimizers.RMSprop(0.001),\n",
    "           metrics=['mae','mse']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 312059 samples\n",
      "Epoch 1/10\n",
      "312059/312059 [==============================] - 20s 63us/sample - loss: 0.0076 - mae: 0.0076 - mse: 0.0019\n",
      "Epoch 2/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 0.0066 - mae: 0.0066 - mse: 0.0012\n",
      "Epoch 3/10\n",
      "312059/312059 [==============================] - 19s 60us/sample - loss: 0.0053 - mae: 0.0053 - mse: 7.6963e-04\n",
      "Epoch 4/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 0.0033 - mae: 0.0033 - mse: 2.3545e-04\n",
      "Epoch 5/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 0.0029 - mae: 0.0029 - mse: 1.8684e-04\n",
      "Epoch 6/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 0.0027 - mae: 0.0027 - mse: 1.6785e-04\n",
      "Epoch 7/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 0.0025 - mae: 0.0025 - mse: 1.4644e-04\n",
      "Epoch 8/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 0.0025 - mae: 0.0025 - mse: 1.4051e-04\n",
      "Epoch 9/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 0.0024 - mae: 0.0024 - mse: 1.3331e-04\n",
      "Epoch 10/10\n",
      "312059/312059 [==============================] - 19s 62us/sample - loss: 0.0023 - mae: 0.0023 - mse: 1.3151e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39c81a50f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(train_input, train_labels, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0026719394062012978, 0.0026719382, 0.00015431074]\n",
      "0.00019661427750170343\n"
     ]
    }
   ],
   "source": [
    "print(nn.evaluate(test_input, test_labels, verbose=0))\n",
    "print(median_absolute_error(test_labels, nn.predict(test_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's change the optimizer. I found \"adam\" to be the most successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.Sequential([\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "nn.compile(loss = 'mae',\n",
    "           optimizer = 'adam',\n",
    "           metrics=['mse']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 312059 samples\n",
      "Epoch 1/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 0.0082 - mse: 0.0012\n",
      "Epoch 2/10\n",
      "312059/312059 [==============================] - 21s 66us/sample - loss: 0.0036 - mse: 2.7338e-04\n",
      "Epoch 3/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 0.0024 - mse: 1.2650e-04\n",
      "Epoch 4/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 0.0021 - mse: 9.0294e-05\n",
      "Epoch 5/10\n",
      "312059/312059 [==============================] - 21s 68us/sample - loss: 0.0019 - mse: 7.5554e-05\n",
      "Epoch 6/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 0.0018 - mse: 7.1071e-05\n",
      "Epoch 7/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 0.0017 - mse: 6.2967e-05\n",
      "Epoch 8/10\n",
      "312059/312059 [==============================] - 21s 68us/sample - loss: 0.0016 - mse: 6.0812e-05\n",
      "Epoch 9/10\n",
      "312059/312059 [==============================] - 21s 68us/sample - loss: 0.0015 - mse: 5.7968e-05\n",
      "Epoch 10/10\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 0.0015 - mse: 5.7182e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39c75e97f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(train_input, train_labels, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0014915586093510297, 3.8463913e-05]\n",
      "0.0002637451980262995\n"
     ]
    }
   ],
   "source": [
    "print(nn.evaluate(test_input, test_labels, verbose=0))\n",
    "print(median_absolute_error(test_labels, nn.predict(test_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5514.74376\n",
      "217.38764112\n"
     ]
    }
   ],
   "source": [
    "max = border_crossing['Value'].max()\n",
    "print(.00124 * max)\n",
    "print(.00004888 * max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.Sequential([\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(len_hidden, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "nn.compile(loss = 'mae',\n",
    "           optimizer = 'adam',\n",
    "           metrics=['mse']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 312059 samples\n",
      "Epoch 1/25\n",
      "312059/312059 [==============================] - 22s 70us/sample - loss: 0.0066 - mse: 0.0030\n",
      "Epoch 2/25\n",
      "312059/312059 [==============================] - 21s 69us/sample - loss: 0.0026 - mse: 1.6296e-04\n",
      "Epoch 3/25\n",
      "312059/312059 [==============================] - 22s 70us/sample - loss: 0.0022 - mse: 1.1850e-04\n",
      "Epoch 4/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0019 - mse: 9.1172e-05\n",
      "Epoch 5/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0018 - mse: 7.9899e-05\n",
      "Epoch 6/25\n",
      "312059/312059 [==============================] - 22s 72us/sample - loss: 0.0017 - mse: 7.2632e-05\n",
      "Epoch 7/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0016 - mse: 6.9011e-05\n",
      "Epoch 8/25\n",
      "312059/312059 [==============================] - 22s 72us/sample - loss: 0.0016 - mse: 6.3343e-05\n",
      "Epoch 9/25\n",
      "312059/312059 [==============================] - 22s 72us/sample - loss: 0.0015 - mse: 6.0308e-05\n",
      "Epoch 10/25\n",
      "312059/312059 [==============================] - 22s 70us/sample - loss: 0.0015 - mse: 6.0026e-05\n",
      "Epoch 11/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0015 - mse: 5.8179e-05\n",
      "Epoch 12/25\n",
      "312059/312059 [==============================] - 22s 69us/sample - loss: 0.0014 - mse: 5.4988e-05\n",
      "Epoch 13/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0014 - mse: 5.2252e-05\n",
      "Epoch 14/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0014 - mse: 5.3735e-05\n",
      "Epoch 15/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0014 - mse: 5.2320e-05\n",
      "Epoch 16/25\n",
      "312059/312059 [==============================] - ETA: 0s - loss: 0.0014 - mse: 5.0996e-0 - 22s 70us/sample - loss: 0.0014 - mse: 5.0923e-05\n",
      "Epoch 17/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0014 - mse: 5.1160e-05\n",
      "Epoch 18/25\n",
      "312059/312059 [==============================] - 21s 67us/sample - loss: 0.0013 - mse: 4.9303e-05\n",
      "Epoch 19/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0013 - mse: 4.9161e-05\n",
      "Epoch 20/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0013 - mse: 4.8895e-05\n",
      "Epoch 21/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0013 - mse: 5.0198e-05\n",
      "Epoch 22/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0013 - mse: 4.7389e-05\n",
      "Epoch 23/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0013 - mse: 4.7423e-05\n",
      "Epoch 24/25\n",
      "312059/312059 [==============================] - 22s 72us/sample - loss: 0.0013 - mse: 4.5865e-05\n",
      "Epoch 25/25\n",
      "312059/312059 [==============================] - 22s 71us/sample - loss: 0.0013 - mse: 4.6346e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39b5b3d080>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(train_input, train_labels, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001153752259198494, 3.183326e-05]\n",
      "9.128908277489245e-05\n"
     ]
    }
   ],
   "source": [
    "print(nn.evaluate(test_input, test_labels, verbose=0))\n",
    "print(median_absolute_error(test_labels, nn.predict(test_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4141.97282742\n",
      "80.58641688\n"
     ]
    }
   ],
   "source": [
    "max = border_crossing['Value'].max()\n",
    "print(.00093133 * max)\n",
    "print(.00001812 * max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I am unable to improve accuracy with the neural network. It is very suprising that the random forest would outperform the neural network. Perhaps this was a result of the unusual value distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
